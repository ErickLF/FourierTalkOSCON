{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io.wavfile\n",
    "import IPython\n",
    "\n",
    "def setup_graph(title='', x_label='', y_label='', fig_size=None):\n",
    "    fig = plt.figure()\n",
    "    if fig_size != None:\n",
    "        fig.set_size_inches(fig_size[0], fig_size[1])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Filtering\n",
    "\n",
    "Procedure:\n",
    "    \n",
    "* Read in audio\n",
    "* Apply STFT (Window and FFT)\n",
    "* Remove a range of frequencies we want out\n",
    "* Apply Inverse STFT (to resynthesize)\n",
    "* Write new audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft(input_data, window_size, hop_size):\n",
    "    window = scipy.hamming(window_size)\n",
    "    output = scipy.array([scipy.fft(window * input_data[i: i + window_size]) \n",
    "                         for i in range(0, len(input_data) - window_size, hop_size)])\n",
    "    return output\n",
    "\n",
    "def istft(input_data, window_size, hop_size, len_signal):\n",
    "    window = scipy.hamming(window_size)\n",
    "    output = np.zeros((len(input_data) - 1) * hop_size + window_size)\n",
    "    for i, in_dat in enumerate(input_data):\n",
    "        ini = i * hop_size\n",
    "        output[ini: ini + window_size] += scipy.real(scipy.ifft(in_dat))\n",
    "    return output\n",
    "\n",
    "def low_pass_filter(max_freq, window_size, sample_rate):\n",
    "    fft_bin_width = sample_rate / (window_size / 2)\n",
    "    max_freq_bin = int(max_freq / fft_bin_width)\n",
    "    filter_block = np.ones(window_size)\n",
    "    filter_block[max_freq_bin: (window_size - max_freq_bin)] = 0\n",
    "    return filter_block\n",
    "\n",
    "def high_pass_filter(min_freq, window_size, sample_rate):\n",
    "    return np.ones(window_size) - low_pass_filter(min_freq, window_size, sample_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_audio(input_signal, filter_window, window_size=256):\n",
    "    # Setting parameters\n",
    "    hop_size = window_size // 2\n",
    "    \n",
    "    # Do actual filtering\n",
    "    stft_output = stft(input_signal, window_size, hop_size)\n",
    "    filtered_result = [stft_window * filter_window for stft_window in stft_output]\n",
    "    resynth = istft(filtered_result, window_size, hop_size, len(input_signal))\n",
    "    \n",
    "    return resynth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"audio_files/ohm_scale.wav\"\n",
    "outfile = \"audio_files/high_pass_out.wav\"\n",
    "window_size = 256\n",
    "\n",
    "# Input\n",
    "(sample_rate, input_signal) = scipy.io.wavfile.read(infile)\n",
    "\n",
    "# Create filter window\n",
    "filter_window = high_pass_filter(2500, window_size, sample_rate)\n",
    "\n",
    "# Run filter\n",
    "resynth = filter_audio(input_signal, filter_window, window_size)\n",
    "\n",
    "# Output\n",
    "scipy.io.wavfile.write(outfile, sample_rate, resynth.astype('int16'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"audio_files/ohm_scale.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"audio_files/high_pass_out.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_graph(title='Spectrogram (Before)', x_label='time (in seconds)', y_label='frequency', fig_size=(14,7))\n",
    "_ = plt.specgram(input_signal, Fs=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_graph(title='Spectrogram (After)', x_label='time (in seconds)', y_label='frequency', fig_size=(14,7))\n",
    "_ = plt.specgram(resynth, Fs=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sound Wave Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_graph(title='Sound wave (Before)', x_label='time (in seconds)', y_label='amplitude', fig_size=(14,7))\n",
    "_ = plt.plot(input_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sound Wave After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_graph(title='Sound wave (After)', x_label='time (in seconds)', y_label='amplitude', fig_size=(14,7))\n",
    "_ = plt.plot(resynth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A low-pass filter example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"audio_files/doremi_xylo.wav\"\n",
    "outfile = \"audio_files/low_pass_out.wav\"\n",
    "window_size = 256\n",
    "\n",
    "# Input\n",
    "(sample_rate, input_signal) = scipy.io.wavfile.read(infile)\n",
    "\n",
    "# Create filter window\n",
    "filter_window = low_pass_filter(1700, window_size, sample_rate)\n",
    "\n",
    "# Run filter\n",
    "resynth = filter_audio(input_signal, filter_window, window_size)\n",
    "\n",
    "# Output\n",
    "scipy.io.wavfile.write(outfile, sample_rate, resynth.astype('int16'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"audio_files/doremi_xylo.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"audio_files/low_pass_out.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that in the after example, you can hear the xylophone mallet, but not the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_graph(title='Sound wave (Before)', x_label='time (in seconds)', y_label='amplitude', fig_size=(14,7))\n",
    "_ = plt.plot(input_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_graph(title='Sound wave (After)', x_label='time (in seconds)', y_label='amplitude', fig_size=(14,7))\n",
    "_ = plt.plot(resynth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
